{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import tensorflow as tf\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection API with TensorFlow 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### API setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download tensorflow 2 object detection api\n",
    "https://github.com/tensorflow/models/tree/master/research/object_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow-gpu 2.10.1\n",
    "# https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/tensorflow/models.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd C:\\Users\\Imtiaz\\Downloads\\DL_models\\models\\research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile protos.\n",
    "!C:\\Users\\Imtiaz\\Downloads\\DL_models\\protobuf\\bin\\protoc.exe object_detection/protos/*.proto --python_out=."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install TensorFlow Object Detection API.\n",
    "'''\n",
    "copy setup.py from object_detection/packages/tf2 inside models/research\n",
    "'''\n",
    "!copy object_detection/packages/tf2/setup.py ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the installation.\n",
    "!python object_detection/builders/model_builder_tf2_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming xml files into one csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_ANNOT_PATH  = \"\"\n",
    "VALID_ANNOT_PATH  = \"\"\n",
    "TEST_ANNOT_PATH  = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.xml_to_csv import generate_csv_file\n",
    "TRAIN_CSV = \"dataset_csv/annotations.csv\"\n",
    "VALID_CSV = \"dataset_csv/annotations_valid.csv\"\n",
    "TEST_CSV  = \"dataset_csv/test_data.csv\"\n",
    "generate_csv_file(TRAIN_ANNOT_PATH, TRAIN_CSV)\n",
    "generate_csv_file(VALID_ANNOT_PATH, VALID_CSV)\n",
    "generate_csv_file(TEST_ANNOT_PATH, TEST_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_CSV = \"dataset_csv/annotations.csv\"\n",
    "VALID_CSV = \"dataset_csv/annotations_valid.csv\"\n",
    "TEST_CSV  = \"dataset_csv/test_data.csv\"\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "valid_df = pd.read_csv(VALID_CSV)\n",
    "test_df  = pd.read_csv(TEST_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_csv(df, indx: list):\n",
    "    df = df.reset_index(drop=True)\n",
    "    length = len(indx)\n",
    "    cnt = 0\n",
    "    if length > 2:\n",
    "        r, c = length//3, 4\n",
    "        _, axis = plt.subplots(r, c, figsize=(16, 10))\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                if cnt > length-1:\n",
    "                    break\n",
    "                img = df.iloc[indx[cnt], :]\n",
    "                file_name = img['filename']\n",
    "                gImg = df[df['filename'] == file_name].reset_index(drop=True)\n",
    "                image = cv2.cvtColor(cv2.imread(file_name), cv2.COLOR_BGR2RGB)\n",
    "                for z in range(gImg.shape[0]):\n",
    "                    class_, xmin, ymin, xmax, ymax = gImg.iloc[z, 3:]\n",
    "                    cv2.rectangle(image, (xmin, ymin),\n",
    "                                  (xmax, ymax), (0, 255, 0), 2)\n",
    "                    cv2.putText(image, f\"{class_}\", (xmin, ymin + 30),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                if r == 1:\n",
    "                    axis[j].imshow(image)\n",
    "                    axis[j].set_xticks([]), axis[j].set_yticks([])\n",
    "                else:\n",
    "                    axis[i, j].imshow(image)\n",
    "                    axis[i, j].set_xticks([]), axis[i, j].set_yticks([])\n",
    "                cnt += 1\n",
    "\n",
    "    else:\n",
    "        r, c = 1, 2\n",
    "        _, axis = plt.subplots(r, c, figsize=(12, 6))\n",
    "        for i in range(length):\n",
    "            img = df.iloc[indx[i], :]\n",
    "            file_name = img['filename']\n",
    "            gImg = df[df['filename'] == file_name].reset_index(drop=True)\n",
    "            image = cv2.cvtColor(cv2.imread(file_name), cv2.COLOR_BGR2RGB)\n",
    "            for z in range(gImg.shape[0]):\n",
    "                class_, xmin, ymin, xmax, ymax = gImg.iloc[z, 3:]\n",
    "                cv2.rectangle(image, (xmin, ymin),\n",
    "                              (xmax, ymax), (0, 255, 0), 2)\n",
    "                cv2.putText(image, f\"{class_}\", (xmin, ymin + 30),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "            axis[i].imshow(image)\n",
    "            axis[i].set_xticks([]), axis[i].set_yticks([])\n",
    "            \n",
    "show_csv(train_df, [1010,900,250,600])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_csv(test_df, [0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_csv(valid_df, [0, 3, 7, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd C:\\Users\\Imtiaz\\Downloads\\DL_models\\utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set\n",
    "!python generate_tfrecords.py --path_to_images C:\\Users\\Imtiaz\\Downloads\\DL_models\\data\\images\\train --path_to_annot C:\\Users\\Imtiaz\\Downloads\\DL_models\\dataset_csv\\annotations.csv --path_to_label_map C:\\Users\\Imtiaz\\Downloads\\DL_models\\annotations\\labelmap.pbtxt --path_to_save_tfrecords C:\\Users\\Imtiaz\\Downloads\\DL_models\\annotations\\train.record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation set\n",
    "!python generate_tfrecords.py --path_to_images C:\\Users\\Imtiaz\\Downloads\\DL_models\\data\\images\\val --path_to_annot C:\\Users\\Imtiaz\\Downloads\\DL_models\\dataset_csv\\annotations_valid.csv --path_to_label_map C:\\Users\\Imtiaz\\Downloads\\DL_models\\annotations\\labelmap.pbtxt --path_to_save_tfrecords C:\\Users\\Imtiaz\\Downloads\\DL_models\\annotations\\val.record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set\n",
    "!python generate_tfrecords.py --path_to_images C:\\Users\\Imtiaz\\Downloads\\DL_models\\data\\images\\test --path_to_annot C:\\Users\\Imtiaz\\Downloads\\DL_models\\dataset_csv\\test_data.csv --path_to_label_map C:\\Users\\Imtiaz\\Downloads\\DL_models\\annotations\\labelmap.pbtxt --path_to_save_tfrecords C:\\Users\\Imtiaz\\Downloads\\DL_models\\annotations\\test.record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfrecord_file = 'C:\\\\Users\\\\Imtiaz\\\\Downloads\\\\DL_models\\\\annotations\\\\train.record'\n",
    "val_tfrecord_file = 'C:\\\\Users\\\\Imtiaz\\\\Downloads\\\\DL_models\\\\annotations\\\\val.record'\n",
    "test_tfrecord_file = 'C:\\\\Users\\\\Imtiaz\\\\Downloads\\\\DL_models\\\\annotations\\\\test.record'\n",
    "label_map = 'C:\\\\Users\\\\Imtiaz\\\\Downloads\\\\DL_models\\\\annotations\\\\labelmap.pbtxt'\n",
    "# Create a TFRecordDataset\n",
    "train_dataset = tf.data.TFRecordDataset([train_tfrecord_file])\n",
    "val_dataset = tf.data.TFRecordDataset([val_tfrecord_file])\n",
    "test_dataset = tf.data.TFRecordDataset([test_tfrecord_file])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in val_dataset.take(2):\n",
    "    example = tf.train.Example()\n",
    "    example.ParseFromString(record.numpy())\n",
    "    print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_cv\n",
    "from keras_cv import bounding_box\n",
    "from keras_cv import visualization\n",
    "def parse_tfrecord_fn(example):\n",
    "    feature_description = {\n",
    "        'image/encoded': tf.io.FixedLenFeature([], tf.string),\n",
    "        'image/height': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'image/width': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'image/object/bbox/xmin': tf.io.VarLenFeature(tf.float32),\n",
    "        'image/object/bbox/xmax': tf.io.VarLenFeature(tf.float32),\n",
    "        'image/object/bbox/ymin': tf.io.VarLenFeature(tf.float32),\n",
    "        'image/object/bbox/ymax': tf.io.VarLenFeature(tf.float32),\n",
    "        'image/object/class/label': tf.io.VarLenFeature(tf.int64),\n",
    "    }\n",
    "    \n",
    "    parsed_example = tf.io.parse_single_example(example, feature_description)\n",
    "\n",
    "    # Decode the JPEG image and normalize the pixel values to the [0, 1] range.\n",
    "    img = tf.image.decode_jpeg(parsed_example['image/encoded'], channels=3) # Returned as uint8\n",
    "    # Normalize the pixel values to [0, 256]\n",
    "    img = tf.image.convert_image_dtype(img, tf.uint8)\n",
    "\n",
    "    # Get the bounding box coordinates and class labels.\n",
    "    xmin = tf.sparse.to_dense(parsed_example['image/object/bbox/xmin'])\n",
    "    xmax = tf.sparse.to_dense(parsed_example['image/object/bbox/xmax'])\n",
    "    ymin = tf.sparse.to_dense(parsed_example['image/object/bbox/ymin'])\n",
    "    ymax = tf.sparse.to_dense(parsed_example['image/object/bbox/ymax'])\n",
    "    labels = tf.sparse.to_dense(parsed_example['image/object/class/label'])\n",
    "\n",
    "    # Stack the bounding box coordinates to create a [num_boxes, 4] tensor.\n",
    "    rel_boxes = tf.stack([xmin, ymin, xmax, ymax], axis=-1)\n",
    "    boxes = keras_cv.bounding_box.convert_format(rel_boxes, source='rel_xyxy', target='xyxy', images=img)\n",
    "\n",
    "    # Create the final dictionary.\n",
    "    image_dataset = {\n",
    "        'images': img,\n",
    "        'bounding_boxes': {\n",
    "            'classes': labels,\n",
    "            'boxes': boxes\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return image_dataset\n",
    "\n",
    "# train_dataset = train_dataset.map(parse_tfrecord_fn)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
