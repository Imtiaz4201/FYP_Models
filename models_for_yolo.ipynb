{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import re\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import time\n",
    "import torch\n",
    "import supervision as sv\n",
    "from ultralytics import YOLO\n",
    "# import albumentations as A\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip uninstall -y albumentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_data(path):\n",
    "    root_path = os.getcwd()\n",
    "    img_paths = []\n",
    "    if os.path.exists(os.path.join(root_path, path)):\n",
    "        for root, dirs, files in os.walk(os.path.join(root_path, path)):\n",
    "            for i in files:\n",
    "                img_paths.append(\n",
    "                    os.path.join(root,i)\n",
    "                )\n",
    "        return img_paths\n",
    "    else:\n",
    "        print(\"folder does not exist\")\n",
    "\n",
    "def count_classes(folder_path, con=\".txt\"):\n",
    "    counts = {\"tm\":0,\"tnb\":0,\"other\":0}\n",
    "    sys_root = os.getcwd()\n",
    "    \n",
    "    if con == \".txt\":\n",
    "        if os.path.exists(os.path.join(sys_root, folder_path)):\n",
    "            for root, _, files in os.walk(os.path.join(sys_root, folder_path)):\n",
    "                for file_name in files:\n",
    "                    if file_name.endswith(con):\n",
    "                        source_path = os.path.join(root, file_name)\n",
    "                        with open(source_path, 'r') as file:\n",
    "                            for line in file:\n",
    "                                values = line.strip().split()\n",
    "                                if values:\n",
    "                                    first_index = int(values[0])\n",
    "                                    if first_index == 0:\n",
    "                                        counts[\"tm\"] += 1\n",
    "                                    elif first_index == 1:\n",
    "                                        counts[\"tnb\"] += 1\n",
    "                                    elif first_index == 2:\n",
    "                                        counts[\"other\"] += 1\n",
    "            return counts\n",
    "        else:\n",
    "            print(\"Folder does not exist\")\n",
    "    elif con == \".xml\":\n",
    "        pass\n",
    "    else:\n",
    "        print(\"No extension found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = read_image_data(\"data\\images/val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_count = count_classes(\"data/labels/train\", \".txt\")\n",
    "test_count = count_classes(\"data/labels/test\", \".txt\")\n",
    "val_count = count_classes(\"data/labels/val\", \".txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axis = plt.subplots(1,3, figsize=(16,6))\n",
    "bars1 = axis[0].bar([*train_count.keys()], [*train_count.values()])\n",
    "axis[0].set_title(\"Train set\")\n",
    "axis[0].set_xlabel(\"Classes\")\n",
    "axis[0].set_ylabel(\"Total\")\n",
    "axis[0].bar_label(bars1)\n",
    "bars2= axis[1].bar([*test_count.keys()], [*test_count.values()])\n",
    "axis[1].set_title(\"Test set\")\n",
    "axis[1].set_xlabel(\"Classes\")\n",
    "axis[1].set_ylabel(\"Total\")\n",
    "axis[1].bar_label(bars2)\n",
    "bars3 = axis[2].bar([*val_count.keys()], [*val_count.values()])\n",
    "axis[2].set_title(\"Validation set\")\n",
    "axis[2].set_xlabel(\"Classes\")\n",
    "axis[2].set_ylabel(\"Total\")\n",
    "axis[2].bar_label(bars3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write csv of train, test, and val (image path, annot path, classes)\n",
    "def text_dataFrame(annots_path, images_path= None):\n",
    "    root_path = os.getcwd()\n",
    "    def read_files(ap):\n",
    "        data = []\n",
    "        for root, dirs, files in os.walk(os.path.join(root_path, ap)):\n",
    "            for i in files:\n",
    "                data.append(\n",
    "                    os.path.join(root, i)\n",
    "                )\n",
    "        return data\n",
    "    \n",
    "    def search_image_path(folder_name):\n",
    "        data = {}\n",
    "        for root, dirs, files in os.walk(os.path.join(root_path, folder_name)):\n",
    "            for i in files:\n",
    "                data[i.split(\".\")[0]] = os.path.join(root, i)\n",
    "        return data\n",
    "    \n",
    "    image_data = search_image_path(images_path)\n",
    "\n",
    "    data_dic = {\"image_path\":[],\"annot_path\": [], \"class_label\": []}\n",
    "    if os.path.exists(os.path.join(root_path, annots_path)):\n",
    "        data = read_files(annots_path)\n",
    "        for i in data:\n",
    "            name = re.findall(re.compile(r\"[a-zA-Z-0-9\\.\\_]+\"), i)[-1]\n",
    "            with open(i, \"r\") as f:\n",
    "                lines = f.readlines()\n",
    "            for line in lines:\n",
    "                data = line.strip().split()  # Assuming space-separated values\n",
    "                class_, x1_, y1_, x2_, y2_ = int(data[0]), float(\n",
    "                    data[1]), float(data[2]), float(data[3]), float(data[4])\n",
    "                an = name.split('.')[0]\n",
    "                data_dic['image_path'].append(image_data[an])\n",
    "                data_dic['annot_path'].append(i)\n",
    "                data_dic['class_label'].append(class_)\n",
    "                #\"image\":data_dic['image_path'],\n",
    "        return pd.DataFrame(\n",
    "            {\n",
    "                \"image\":data_dic['image_path'],\"annot\": data_dic['annot_path'], \"Class\": data_dic['class_label']\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        print(\"path does not exist\")\n",
    "\n",
    "\n",
    "train_df = text_dataFrame(\"data/labels/train\", \"data/images/train\")\n",
    "# test_df = text_dataFrame(\"data/labels/test\", \"data/images/test\")\n",
    "# val_df = text_dataFrame(\"data/labels/validation\", \"data/images/validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tm = train_df[train_df['Class'] == 0]\n",
    "# tnb = train_df[train_df['Class'] == 1]\n",
    "# other = train_df[train_df['Class'] == 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(data, to_save, process):\n",
    "    root_path = os.getcwd()\n",
    "    if os.path.exists(os.path.join(root_path, to_save)):\n",
    "        for i in data:\n",
    "            p = process(i)\n",
    "            name = re.findall(re.compile(r\"[a-zA-Z-0-9\\.\\_]+\"),i)[-1]\n",
    "            cv2.imwrite(os.path.join(root_path, to_save, name),p)\n",
    "        print(\"image writing done.\")\n",
    "    else:\n",
    "        print(f\"{to_save} folder does not exist!\")\n",
    "    \n",
    "def smoothing(img):\n",
    "    img = cv2.imread(img)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    denoised_image = cv2.bilateralFilter(img, 3,10,10)\n",
    "    return denoised_image\n",
    "\n",
    "def contrast_enhance(image):\n",
    "    from CE_modified import ContastEnhancement\n",
    "    #denoised_image = smoothing(image)\n",
    "    img = cv2.imread(image)\n",
    "    ce = ContastEnhancement(img)\n",
    "    processed_image = ce.prcoess_image()\n",
    "    return processed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(image, annot):\n",
    "    def read_yolo_annotation(annotation_file):\n",
    "        with open(annotation_file, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "            annotations = [list(map(float, line.strip().split()))\n",
    "                           for line in lines]\n",
    "        return annotations\n",
    "\n",
    "    def draw_boxes(image_path, annotation_file):\n",
    "        # Read image\n",
    "        image = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Read bounding box annotations\n",
    "        annotations = read_yolo_annotation(annotation_file)\n",
    "\n",
    "        # Draw bounding boxes on the image\n",
    "        for annotation in annotations:\n",
    "            _, center_x, center_y, width, height = annotation\n",
    "            x, y, w, h = int((center_x - width / 2) * image.shape[1]), int(\n",
    "                (center_y - height / 2) * image.shape[0]), int(width * image.shape[1]), int(height * image.shape[0])\n",
    "            cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        plt.imshow(image)\n",
    "\n",
    "    draw_boxes(image, annot)\n",
    "\n",
    "\n",
    "def apply_augment(image_path, annot_path, exclude=None):\n",
    "    transform = A.Compose([\n",
    "        A.HorizontalFlip(p=1)\n",
    "    ], bbox_params=A.BboxParams(format='yolo'))\n",
    "\n",
    "    root_path = os.getcwd()\n",
    "    if os.path.exists(os.path.join(root_path, image_path)) and os.path.exists(os.path.join(root_path, annot_path)):\n",
    "        image = cv2.imread(os.path.join(root_path, image_path))\n",
    "        with open(os.path.join(root_path, annot_path), \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "        bboxes = []\n",
    "        classes = []\n",
    "        for line in lines:\n",
    "            data = line.strip().split()\n",
    "            class_, x1_, y1_, x2_, y2_ = int(data[0]), float(\n",
    "                data[1]), float(data[2]), float(data[3]), float(data[4])\n",
    "            # YOLO format\n",
    "            bboxes.append([x1_, y1_, x2_, y2_, str(class_)])\n",
    "            classes.append(class_)\n",
    "        transformed = transform(image=image, bboxes=bboxes)\n",
    "        transformed_image = transformed['image']\n",
    "        transformed_bboxes = transformed['bboxes']\n",
    "        return transformed_image, transformed_bboxes\n",
    "    else:\n",
    "        print(\"not found!\")\n",
    "\n",
    "\n",
    "def write_annotated_image(name, path, tm):\n",
    "    to_save = os.path.join(os.getcwd(), path, name)\n",
    "    cv2.imwrite(to_save, tm)\n",
    "\n",
    "\n",
    "def write_yolo_annot(name, path, transformed_bboxes):\n",
    "    list_ = []\n",
    "    for i in transformed_bboxes:\n",
    "        l = list(i)\n",
    "        temp = l[-1]\n",
    "        l.remove(l[-1])\n",
    "        l.insert(0, temp)\n",
    "        list_.append(l)\n",
    "    to_save = os.path.join(os.getcwd(), path, name)\n",
    "    with open(to_save, 'w') as file:\n",
    "        for annotation in list_:\n",
    "            line = ' '.join([str(item) for item in annotation]) + '\\n'\n",
    "            file.write(line)\n",
    "\n",
    "def apply1(dataset, ex, tp, loop):\n",
    "    annot_ = dataset['annot'].values\n",
    "    for i, v in enumerate(dataset['image']):\n",
    "        for t in range(loop):\n",
    "            name = re.findall(re.compile(r\"[a-zA-Z-0-9\\_\\.]+\"), v)[-1]\n",
    "            n = name.split(\".\")[0]\n",
    "            an = annot_[i]\n",
    "            transformed_image, transformed_bboxes = apply_augment(\n",
    "                v, an, exclude=ex)\n",
    "            write_annotated_image(f\"{n}AUG{tp}{t}.png\", \"data/images/train\", transformed_image)\n",
    "            write_yolo_annot(f\"{n}AUG{tp}{t}.txt\", \"data/labels/train\", transformed_bboxes)\n",
    "\n",
    "\n",
    "def delete_aug(path):\n",
    "    folder_path = path\n",
    "    files = os.listdir(folder_path)\n",
    "    for file_name in files:\n",
    "        if \"AUG\" in file_name:\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            os.remove(file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo8_model = YOLO('yolov5s.yaml')\n",
    "yolo8_model = YOLO(\"yolov5s.pt\")\n",
    "yolo8_model.to('cuda')\n",
    "yolo8_results = yolo8_model.train(\n",
    "    data='assets.yaml',\n",
    "    imgsz = 896,\n",
    "    epochs=100,\n",
    "    batch=32,\n",
    "    device=0,\n",
    "    verbose=False,\n",
    "    val=True,\n",
    "    optimizer=\"AdamW\",\n",
    "    lr0 = 0.001,\n",
    "    lrf = 0.01,\n",
    "    patience=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo8_model = YOLO('yolov8s.yaml')\n",
    "yolo8_model = YOLO(\"yolov8s.pt\")\n",
    "yolo8_model.to('cuda')\n",
    "yolo8_results = yolo8_model.train(\n",
    "    data='assets.yaml',\n",
    "    imgsz = 896,\n",
    "    epochs=100,\n",
    "    batch=32,\n",
    "    device=0,\n",
    "    verbose=False,\n",
    "    val=True,\n",
    "    optimizer=\"AdamW\",\n",
    "    lr0 = 0.001,\n",
    "    lrf = 0.01,\n",
    "    patience=50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = []\n",
    "test_annot = []\n",
    "def read_test_data(path):\n",
    "    data = []\n",
    "    for root, dirs, files in os.walk(os.path.join(os.getcwd(),path)):\n",
    "        for i in files:\n",
    "            data.append(os.path.join(root,i))\n",
    "    return data\n",
    "test_images = read_test_data(\"data\\\\images\\\\test\")\n",
    "test_annot = read_test_data(\"data\\\\labels\\\\test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(image_dir, annot_dir, classes, model, conf_threshold=0.5, iou_threshold=0.5):\n",
    "    if os.path.exists(os.path.join(os.getcwd(), image_dir)) and os.path.exists(os.path.join(os.getcwd(), annot_dir)):\n",
    "        dataset = sv.DetectionDataset.from_yolo(\n",
    "            images_directory_path=image_dir,\n",
    "            annotations_directory_path=annot_dir,\n",
    "            data_yaml_path=classes,\n",
    "        )\n",
    "\n",
    "        def callback(image: np.ndarray) -> sv.Detections:\n",
    "            result = model(image)[0]\n",
    "            return sv.Detections.from_ultralytics(result)\n",
    "\n",
    "        confusion_matrix = sv.ConfusionMatrix.benchmark(\n",
    "            dataset=dataset,\n",
    "            callback=callback,\n",
    "            conf_threshold=conf_threshold,\n",
    "            iou_threshold=iou_threshold\n",
    "        )\n",
    "        confusion_matrix.plot(fig_size=(12, 6))\n",
    "    else:\n",
    "        print(\"path does not exists\")\n",
    "\n",
    "\n",
    "def get_confusion_matrix(image_dir, annot_dir, classes, model,conf_threshold=0.5, iou_threshold=0.5):\n",
    "    if os.path.exists(os.path.join(os.getcwd(), image_dir)) and os.path.exists(os.path.join(os.getcwd(), annot_dir)):\n",
    "        dataset = sv.DetectionDataset.from_yolo(\n",
    "            images_directory_path=image_dir,\n",
    "            annotations_directory_path=annot_dir,\n",
    "            data_yaml_path=classes,\n",
    "        )\n",
    "\n",
    "        def callback(image: np.ndarray) -> sv.Detections:\n",
    "            result = model(image)[0]\n",
    "            return sv.Detections.from_ultralytics(result)\n",
    "\n",
    "        confusion_matrix = sv.ConfusionMatrix.benchmark(\n",
    "            dataset=dataset,\n",
    "            callback=callback,\n",
    "            conf_threshold=conf_threshold,\n",
    "            iou_threshold=iou_threshold\n",
    "        )\n",
    "        cm = confusion_matrix.matrix\n",
    "        classes_ = confusion_matrix.classes\n",
    "        return cm, classes_\n",
    "    else:\n",
    "        print(\"path does not exists\")\n",
    "\n",
    "\n",
    "def calculate_meanAveragePrecision(image_dir, annot_dir, classes, model):\n",
    "    dataset = sv.DetectionDataset.from_yolo(\n",
    "        images_directory_path=image_dir,\n",
    "        annotations_directory_path=annot_dir,\n",
    "        data_yaml_path=classes,\n",
    "    )\n",
    "\n",
    "    def callback(image: np.ndarray) -> sv.Detections:\n",
    "        result = model(image)[0]\n",
    "        return sv.Detections.from_ultralytics(result)\n",
    "\n",
    "    mean_average_precision = sv.MeanAveragePrecision.benchmark(\n",
    "        dataset=dataset,\n",
    "        callback=callback\n",
    "    )\n",
    "\n",
    "    return {'mAP50': mean_average_precision.map50,\n",
    "            'mAP50_95': mean_average_precision.map50_95}\n",
    "\n",
    "\n",
    "def calculate_precision_multi_class(confusion_matrix):\n",
    "    num_classes = confusion_matrix.shape[0]\n",
    "    precision_per_class = []\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        true_positives = confusion_matrix[i, i]\n",
    "        false_positives = np.sum(confusion_matrix[:, i]) - true_positives\n",
    "        denominator = true_positives + false_positives\n",
    "\n",
    "        if denominator == 0:\n",
    "            precision_per_class.append(0.0)\n",
    "        else:\n",
    "            precision_per_class.append(true_positives / denominator)\n",
    "\n",
    "    return precision_per_class\n",
    "\n",
    "\n",
    "def calculate_recall_multi_class(confusion_matrix):\n",
    "    num_classes = confusion_matrix.shape[0]\n",
    "    recall_per_class = []\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        true_positives = confusion_matrix[i, i]\n",
    "        false_negatives = np.sum(confusion_matrix[i, :]) - true_positives\n",
    "        denominator = true_positives + false_negatives\n",
    "\n",
    "        if denominator == 0:\n",
    "            recall_per_class.append(0.0)\n",
    "        else:\n",
    "            recall_per_class.append(true_positives / denominator)\n",
    "\n",
    "    return recall_per_class\n",
    "\n",
    "\n",
    "def calculate_f1_score_multi_class(confusion_matrix):\n",
    "    num_classes = confusion_matrix.shape[0]\n",
    "    f1_score_per_class = []\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        true_positives = confusion_matrix[i, i]\n",
    "        false_positives = np.sum(confusion_matrix[:, i]) - true_positives\n",
    "        false_negatives = np.sum(confusion_matrix[i, :]) - true_positives\n",
    "        precision = true_positives / (true_positives + false_positives)\n",
    "        recall = true_positives / (true_positives + false_negatives)\n",
    "\n",
    "        if precision + recall == 0:\n",
    "            f1_score_per_class.append(0.0)\n",
    "        else:\n",
    "            f1_score_per_class.append(\n",
    "                2 * (precision * recall) / (precision + recall))\n",
    "\n",
    "    return f1_score_per_class\n",
    "\n",
    "\n",
    "def plot(data, c1,c2):\n",
    "    df = pd.read_csv(data)\n",
    "    df.columns = df.columns.str.strip()\n",
    "    df[[c1,c2]].plot(kind=\"line\")\n",
    "\n",
    "def read_annotations_from_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        annotations = [list(map(float, line.strip().split())) for line in file]\n",
    "    return annotations\n",
    "\n",
    "\n",
    "\n",
    "def plot_test(original: list, model):\n",
    "    class_map = {'0':'tm','1':'tnb','2':'other'}\n",
    "    fig, axis = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    img, annot = original[0], original[1]\n",
    "    annotations = read_annotations_from_file(annot)\n",
    "    pred = model.predict(cv2.resize(img, (640,640)), conf=0.4)\n",
    "    axis[0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    # Draw bounding boxes on the image\n",
    "    for annotation in annotations:\n",
    "        class_id, center_x, center_y, width, height = annotation\n",
    "        x, y, w, h = int((center_x - width / 2) * img.shape[1]), int(\n",
    "            (center_y - height / 2) * img.shape[0]), int(width * img.shape[1]), int(height * img.shape[0])\n",
    "        class_name = class_map[str(int(class_id))]\n",
    "        #label = f'{class_name} ({class_id})'\n",
    "        rect = plt.Rectangle((x, y), w, h, linewidth=1, edgecolor='r', facecolor='none')\n",
    "        axis[0].add_patch(rect)\n",
    "        axis[0].text(x, y+30, class_name, color='r', verticalalignment='bottom', bbox={'facecolor': 'white', 'alpha': 0.7, 'pad': 2})\n",
    "    \n",
    "    res_plot = pred[0].plot()\n",
    "    axis[0].set_title('Original with YOLO Annotation')\n",
    "    axis[1].imshow(cv2.cvtColor(res_plot, cv2.COLOR_BGR2RGB))\n",
    "    axis[1].set_title('YOLO Prediction')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_met, cls = get_confusion_matrix()\n",
    "precision_per_class = calculate_precision_multi_class(con_met)\n",
    "recall_per_class = calculate_recall_multi_class(con_met)\n",
    "f1_score_per_class = calculate_f1_score_multi_class(con_met)\n",
    "\n",
    "print(f'Precision per class: {precision_per_class}')\n",
    "print(f'Recall per class: {recall_per_class}')\n",
    "print(f'F1 score per class: {f1_score_per_class}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mAP 50 and 50_95\n",
    "map = calculate_meanAveragePrecision()\n",
    "print(map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot predicted image\n",
    "classes = {\n",
    "    0: \"tm\",\n",
    "    1: \"tnb\",\n",
    "    2: \"light pole\"\n",
    "}\n",
    "\n",
    "colors = {\n",
    "    \"tm\": (0,255,128),\n",
    "    \"tnb\": (0, 255, 255),\n",
    "    \"light pole\": (204,255,153)\n",
    "}\n",
    "for i in range(len(test_images)):\n",
    "    name = re.findall(re.compile(r\"[a-zA-Z-0-9\\_]+\"), test_images[i])[-2]\n",
    "    img = cv2.imread(test_images[i])\n",
    "    img = cv2.resize(img, (416, 640))\n",
    "    pred = model.predict(img, conf=0.8)\n",
    "    for result in pred:\n",
    "        xywh = result.boxes.xywh\n",
    "        cls = result.boxes.cls\n",
    "        conf_ = result.boxes.conf\n",
    "        for j in range(len(xywh)):\n",
    "            x, y, w, h = xywh[j].cpu().numpy()\n",
    "            c_name = classes[int(cls[j])]\n",
    "            single_conf = round(float(conf_.cpu().numpy()[j]),2)\n",
    "            # Convert from xywh to x1, y1, x2, y2\n",
    "            x1 = int(x - w / 2)\n",
    "            y1 = int(y - h / 2)\n",
    "            x2 = int(x + w / 2)\n",
    "            y2 = int(y + h / 2)\n",
    "\n",
    "            # Draw the bounding box\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), colors[c_name], 1)\n",
    "\n",
    "            (text_width, text_height), baseline = cv2.getTextSize(\n",
    "                f\"{c_name} {single_conf}\", cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)\n",
    "\n",
    "            # Draw a filled rectangle for the text background\n",
    "            cv2.rectangle(img, (x1, y1 - text_height - baseline - 5),\n",
    "                          (x1 + text_width, y1), colors[c_name], thickness=cv2.FILLED)\n",
    "\n",
    "            cv2.putText(img, f\"{c_name} {single_conf}\", (x1, y1 - baseline - 5),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "YOLO_OD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
