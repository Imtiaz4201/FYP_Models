{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = np.array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy\n",
    "class_labels = [\"TM\", \"TNB\", \"Light Pole\", \"Ground\"]\n",
    "correct = np.diagonal(confusion_matrix).sum()\n",
    "total = confusion_matrix.sum()\n",
    "accuracy = correct / total\n",
    "print(f\"Multiclass Accuracy: {accuracy:.4f}\")\n",
    "for i, label in enumerate(class_labels):\n",
    "    if total > 0:\n",
    "        class_accuracy = confusion_matrix[i, i] / total\n",
    "        print(f\"Accuracy ({label}): {class_accuracy:.4f}\")\n",
    "    else:\n",
    "        print(f\"Accuracy ({label}): N/A (no data)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix\n",
    "class_names = ['tm', 'tnb', 'light pole', 'ground']\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.set_theme(font_scale=1.2)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Oranges\",\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate precision, Recall and F1 score\n",
    "n_classes = 3\n",
    "for c in range(n_classes):\n",
    "    tp = conf_matrix[c,c]\n",
    "    fp = sum(conf_matrix[:,c]) - conf_matrix[c,c]\n",
    "    fn = sum(conf_matrix[c,:]) - conf_matrix[c,c]\n",
    "    tn = sum(np.delete(sum(conf_matrix)-conf_matrix[c,:],c))\n",
    "\n",
    "    recall = tp/(tp+fn)\n",
    "    precision = tp/(tp+fp)\n",
    "    f1_score = 2*((precision*recall)/(precision+recall))\n",
    "    \n",
    "    print(\"for class {}: recall {}\\\n",
    "          precision {}, f1 {}\".format(c,round(recall,2), round(precision,2),round(f1_score,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load faster rcnn loss data (train)\n",
    "train_box_loss_cv = \"\"\n",
    "train_box_loss_cv = pd.read_csv(train_box_loss_cv)\n",
    "train_class_loss_cv = \"\"\n",
    "train_class_loss_cv = pd.read_csv(train_class_loss_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load faster rcnn loss data (validation)\n",
    "val_box_loss_cv = \"\"\n",
    "val_box_loss_cv = pd.read_csv(val_box_loss_cv)\n",
    "val_class_loss_cv = \"\"\n",
    "val_class_loss_cv = pd.read_csv(val_class_loss_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loss data\n",
    "train_losses = train_box_loss_cv['Value']\n",
    "train_steps = train_box_loss_cv['Step']\n",
    "# Validation loss data\n",
    "val_losses = val_box_loss_cv['Value'] \n",
    "val_steps = val_box_loss_cv['Step'] \n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(train_steps, train_losses, label='Training Localization Loss', marker='o')\n",
    "plt.plot(val_steps, val_losses, label='Validation Localization Loss', marker='o')\n",
    "\n",
    "plt.title('Training and Validation Localization Losses')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(False)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loss data\n",
    "train_losses = train_class_loss_cv['Value']\n",
    "train_steps = train_class_loss_cv['Step']\n",
    "# Validation loss data\n",
    "val_losses = val_class_loss_cv['Value']\n",
    "val_steps = val_class_loss_cv['Step']\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(train_steps, train_losses, label='Training Classification Loss', marker='o')\n",
    "plt.plot(val_steps, val_losses, label='Validation Classification Loss', marker='o')\n",
    "\n",
    "plt.title('Training and Validation Classification Losses')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(False)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read yolo results\n",
    "yoloRes = pd.read_csv('')\n",
    "yoloRes.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loss data\n",
    "train_losses = yoloRes['         train/box_loss']\n",
    "train_steps = np.array(range(0, yoloRes.shape[0]))\n",
    "# Validation loss data\n",
    "val_losses = yoloRes['           val/box_loss']\n",
    "val_steps = np.array(range(0, yoloRes.shape[0]))\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(train_steps, train_losses, label='Training Box Loss', marker='o')\n",
    "plt.plot(val_steps, val_losses, label='Validation Box Loss', marker='o')\n",
    "\n",
    "plt.title('Training and Validation Box Losses')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loss data\n",
    "train_losses = yoloRes['         train/cls_loss']\n",
    "train_steps =np.array(range(0, yoloRes.shape[0]))\n",
    "# Validation loss data\n",
    "val_losses = yoloRes['           val/cls_loss']\n",
    "val_steps = np.array(range(0, yoloRes.shape[0]))\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(train_steps, train_losses, label='Training Classification Loss', marker='o')\n",
    "plt.plot(val_steps, val_losses, label='Validation Classification Loss', marker='o')\n",
    "\n",
    "plt.title('Training and Validation Classification Losses')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
